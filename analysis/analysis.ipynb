{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil.parser import parse\n",
    "from utils import mean_2d_diff_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = \"../logs/\"\n",
    "objs_in_path = listdir(LOGS_PATH)\n",
    "data_paths = [join(LOGS_PATH, f) for f in objs_in_path if isfile(join(LOGS_PATH, f)) and 'batch_100' in f and 'epochs_1000' in f and 'json' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "for path in data_paths:\n",
    "    with open(path) as f:\n",
    "        d = json.load(f)\n",
    "    logs.append(json_normalize(d))\n",
    "data = pd.concat(logs, axis=0, ignore_index=True)\n",
    "for field in ['end_time', 'start-time', 'start-compute-time', 'end-compute-time']:\n",
    "    data[field] = data[field].apply(parse)\n",
    "data['compute-time'] = (data['end-compute-time'] - data['start-compute-time'])/np.timedelta64(1, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Hogwild!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [join(LOGS_PATH, f) for f in objs_in_path if isfile(join(LOGS_PATH, f)) and 'hogwild' in f and 'json' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "for path in data_paths:\n",
    "    with open(path) as f:\n",
    "        d = json.load(f)\n",
    "    logs.append(json_normalize(d))\n",
    "data_hog = pd.concat(logs, axis=0, ignore_index=True)\n",
    "data_hog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hog['losses_val'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hogwild\n",
    "by_sync = data_hog.groupby('running_mode')\n",
    "for rmode in by_sync:\n",
    "    mode = rmode[0]\n",
    "    times = []\n",
    "    workers = []\n",
    "    for w_count in rmode[1].groupby('n_workers'):\n",
    "        work = int(w_count[0])\n",
    "        workers.append(work)\n",
    "        time = np.mean(w_count[1]['running_time'].values)\n",
    "        times.append(time)\n",
    "    zipped_sorted = sorted(zip(workers, times), key=lambda x: x[0])\n",
    "    (workers, times) = zip(*zipped_sorted)\n",
    "    plt.plot(workers, times, 'o-', label=mode.capitalize())\n",
    "\n",
    "### Spark\n",
    "by_workers = data.groupby('num_workers')\n",
    "times = []\n",
    "workers = []\n",
    "for i in by_workers:\n",
    "    compute_time = i[1]['compute-time']\n",
    "    workers.append(i[0])\n",
    "    times.append(np.mean(compute_time))\n",
    "\n",
    "plt.plot(workers, times, 'o-', label='Spark')\n",
    "### plot\n",
    "plt.rc('font', size=12)\n",
    "plt.xlabel('#Workers')\n",
    "plt.ylabel('Running Time (s)')\n",
    "plt.xticks(workers)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hogwild\n",
    "by_sync = data_hog.groupby('running_mode')\n",
    "for rmode in by_sync:\n",
    "    mode = rmode[0]\n",
    "    accs = []\n",
    "    workers = []\n",
    "    for w_count in rmode[1].groupby('n_workers'):\n",
    "        work = int(w_count[0])\n",
    "        workers.append(work)\n",
    "        acc = np.mean(w_count[1]['accuracy_test'].values)\n",
    "        accs.append(acc)\n",
    "    zipped_sorted = sorted(zip(workers, accs), key=lambda x: x[0])\n",
    "    (workers, accs) = zip(*zipped_sorted)\n",
    "    plt.plot(workers, accs, 'o-', label=mode.capitalize())\n",
    "\n",
    "    \n",
    "### Spark\n",
    "by_workers = data.groupby('num_workers')\n",
    "test_accs = []\n",
    "workers = []\n",
    "for i in by_workers:\n",
    "    acc = np.array(i[1]['test_accuracy'].values)\n",
    "    workers.append(i[0])\n",
    "    test_accs.append(np.mean(acc))\n",
    "plt.plot(workers, test_accs, 'o-', label=\"Spark\")\n",
    "\n",
    "### General plot info\n",
    "plt.rc('font', size=12)\n",
    "plt.xlabel('#Workers')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.xticks(workers)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3,1,figsize=(20,15), sharex=True)\n",
    "\n",
    "## Spark\n",
    "by_workers = data.groupby('num_workers')\n",
    "for i in by_workers:\n",
    "    epoch_history = i[1]['epochs-stats'].values\n",
    "    worker_ttstamps = []\n",
    "    worker_losses = []\n",
    "    for stat in epoch_history:\n",
    "        start_time = parse(stat[0]['epoch_start'])\n",
    "        #list of timestamps for this run\n",
    "        time_stamps = [(parse(epoch['epoch_start']) - start_time).total_seconds() for epoch in stat]\n",
    "#         print(time_stamps)\n",
    "        worker_ttstamps.append(time_stamps)\n",
    "        \n",
    "        #list of losses for this run\n",
    "        losses = [epoch['val_loss'] for epoch in stat]\n",
    "        worker_losses.append(losses)\n",
    "    \n",
    "    #average this shit\n",
    "    mean_worker_ttstamps = mean_2d_diff_size(worker_ttstamps)\n",
    "    mean_losses = mean_2d_diff_size(worker_losses)\n",
    "    ax1.set_title('Spark')\n",
    "    ax1.plot(mean_worker_ttstamps, mean_losses, \n",
    "             label=\"{} Worker(s)\".format(i[0]), \n",
    "             linewidth=4)\n",
    "    ax1.legend()\n",
    "## Hogwild\n",
    "by_mode = data_hog.groupby('running_mode')\n",
    "for m in by_mode:\n",
    "    mode = m[0]\n",
    "    by_workers = m[1].groupby('n_workers')\n",
    "    ax = ax2 if mode == 'asynchronous' else ax3\n",
    "    for w in sorted(by_workers,key=lambda x: int(x[0])):\n",
    "        num_workers = w[0]\n",
    "        worker_all_timestamps = []\n",
    "        worker_all_losses = []\n",
    "        for run in w[1]['losses_val']:\n",
    "            initial_time = parse(run[0]['time'])\n",
    "            this_run_timestamps = [(parse(epoch['time']) - initial_time)\\\n",
    "                                   .total_seconds()\n",
    "                                   for epoch in run]\n",
    "#             print(len(this_run_timestamps), thi\n",
    "            worker_all_timestamps.append(this_run_timestamps)\n",
    "            this_run_losses = [epoch['loss_val'] for epoch in run]\n",
    "            worker_all_losses.append(this_run_losses)\n",
    "#         print(worker_all_timestamps)\n",
    "        worker_mean_timestamps = mean_2d_diff_size(worker_all_timestamps)\n",
    "        worker_mean_losses = mean_2d_diff_size(worker_all_losses)\n",
    "        \n",
    "        ax.plot(worker_mean_timestamps, worker_mean_losses, \n",
    "                label = \"{} Workers\".format(num_workers),\n",
    "                linewidth=4)\n",
    "        ax.set_title(mode)\n",
    "        ax.legend()\n",
    "for ax in ax1, ax2, ax3:  \n",
    "    ax.set_ylabel('Validation Loss')\n",
    "\n",
    "plt.xlabel('Execution Time (s)')\n",
    "plt.rc('font', size=18)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
